{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CudaNumpy",
      "provenance": [],
      "authorship_tag": "ABX9TyPLIXWuVupNGi2zdljkpLh2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mleyvaz/computacion-paralela/blob/main/CudaNumpy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSEsO9yv-UHA",
        "outputId": "399e19d4-2333-4f4f-d7b9-6a87fa5617c8"
      },
      "source": [
        "from numba import cuda\n",
        "import numpy\n",
        "print(cuda.gpus)\n",
        "import math"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Managed Device 0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZfL8M9ODApR"
      },
      "source": [
        "@cuda.jit\n",
        "def matmul(A, B, C):\n",
        "    \"\"\"Perform matrix multiplication of C = A * B\n",
        "    \"\"\"\n",
        "    row, col = cuda.grid(2)\n",
        "    if row < C.shape[0] and col < C.shape[1]:\n",
        "        tmp = 0.\n",
        "        for k in range(A.shape[1]):\n",
        "            tmp += A[row, k] * B[k, col]\n",
        "        C[row, col] = tmp"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4nNLgvMDcf6",
        "outputId": "6df71c56-e198-48b8-e8ef-e33e4fab5dbc"
      },
      "source": [
        "# Initialize the data arrays\n",
        "A = numpy.full((24, 12), 3, numpy.float) # matrix containing all 3's\n",
        "B = numpy.full((12, 22), 4, numpy.float) # matrix containing all 4's\n",
        "\n",
        "# Copy the arrays to the device\n",
        "A_global_mem = cuda.to_device(A)\n",
        "B_global_mem = cuda.to_device(B)\n",
        "\n",
        "# Allocate memory on the device for the result\n",
        "C_global_mem = cuda.device_array((24, 22))\n",
        "\n",
        "# Configure the blocks\n",
        "threadsperblock = (16, 16)\n",
        "blockspergrid_x = int(math.ceil(A.shape[0] / threadsperblock[0]))\n",
        "blockspergrid_y = int(math.ceil(B.shape[1] / threadsperblock[1]))\n",
        "blockspergrid = (blockspergrid_x, blockspergrid_y)\n",
        "\n",
        "# Start the kernel \n",
        "matmul[blockspergrid, threadsperblock](A_global_mem, B_global_mem, C_global_mem)\n",
        "\n",
        "# Copy the result back to the host\n",
        "C = C_global_mem.copy_to_host()\n",
        "\n",
        "print(C)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
            "  144. 144. 144. 144. 144. 144. 144. 144.]\n",
            " [144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
            "  144. 144. 144. 144. 144. 144. 144. 144.]\n",
            " [144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
            "  144. 144. 144. 144. 144. 144. 144. 144.]\n",
            " [144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
            "  144. 144. 144. 144. 144. 144. 144. 144.]\n",
            " [144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
            "  144. 144. 144. 144. 144. 144. 144. 144.]\n",
            " [144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
            "  144. 144. 144. 144. 144. 144. 144. 144.]\n",
            " [144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
            "  144. 144. 144. 144. 144. 144. 144. 144.]\n",
            " [144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
            "  144. 144. 144. 144. 144. 144. 144. 144.]\n",
            " [144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
            "  144. 144. 144. 144. 144. 144. 144. 144.]\n",
            " [144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
            "  144. 144. 144. 144. 144. 144. 144. 144.]\n",
            " [144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
            "  144. 144. 144. 144. 144. 144. 144. 144.]\n",
            " [144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
            "  144. 144. 144. 144. 144. 144. 144. 144.]\n",
            " [144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
            "  144. 144. 144. 144. 144. 144. 144. 144.]\n",
            " [144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
            "  144. 144. 144. 144. 144. 144. 144. 144.]\n",
            " [144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
            "  144. 144. 144. 144. 144. 144. 144. 144.]\n",
            " [144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
            "  144. 144. 144. 144. 144. 144. 144. 144.]\n",
            " [144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
            "  144. 144. 144. 144. 144. 144. 144. 144.]\n",
            " [144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
            "  144. 144. 144. 144. 144. 144. 144. 144.]\n",
            " [144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
            "  144. 144. 144. 144. 144. 144. 144. 144.]\n",
            " [144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
            "  144. 144. 144. 144. 144. 144. 144. 144.]\n",
            " [144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
            "  144. 144. 144. 144. 144. 144. 144. 144.]\n",
            " [144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
            "  144. 144. 144. 144. 144. 144. 144. 144.]\n",
            " [144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
            "  144. 144. 144. 144. 144. 144. 144. 144.]\n",
            " [144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144. 144.\n",
            "  144. 144. 144. 144. 144. 144. 144. 144.]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}